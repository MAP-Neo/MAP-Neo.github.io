<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="MAP-Neo" />
    <meta property="og:description" content="Towards Building Generalist Models for Structured Knowledge Grounding" />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>MAP-Neo</title>
    <link rel="icon" href="./static/images/map-logo.png">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="static/js/jquery.min.js"></script>
    <script src="static/js/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>

    <link rel="stylesheet" type="text/css" href="static/css/jquery.dataTables.css">
    <script type="text/javascript" charset="utf8" src="static/js/jquery-3.5.1.js"></script>
    <script type="text/javascript" charset="utf8" src="static/js/jquery.dataTables.js"></script>
    <style>
        /* #special-table tbody tr td:nth-child(0),
        #special-table tbody tr td:nth-child(1) {
            padding-right: 30px;
        }
        #special-table tbody tr td:nth-child(0),
        #special-table tbody tr td:nth-child(1) {
            padding-left: 30px;
        } */

        .number-box {
            border: 1px solid #000; /* ÈªëËâ≤ËæπÊ°Ü */
            padding: 3px; /* ÂÜÖËæπË∑ù */
            margin: 3px; /* Â§ñËæπË∑ù */
        }
    </style>
    
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">
                            <style>
                                .logo {
                                  width: 1em; /* Ë∞ÉÊï¥ÂõæÊ†áÂ§ßÂ∞è */
                                  position: relative; /* ‰Ωø top Âíå left Â±ûÊÄßÁîüÊïà */
                                  top: -10px; /* Âêë‰∏äÁßªÂä® */
                                  left: -5px; /* ÂêëÂ∑¶ÁßªÂä® */
                                  vertical-align: middle;
                                }
                              </style>
                              <img src="static/images/map-logo.png" class="logo" alt="Logo" />
                              MAP-Neo: <br>
                              Highly Capable and Transparent Bilingual<br>Large Language Model Series
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            
                        </div>



                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                M-A-P,
                                University of Waterloo,
                                Wuhan AI Research,
                                01.AI 
                                <!-- <sup>1</sup>M-A-P,
                                <sup>2</sup>University of Waterloo,
                                <sup>3</sup>Wuhan AI Research,
                                <sup>4</sup>01.AI, -->
                        </div>

    
                        <div class="column has-text-centered">
                            <div class="publication-links">

                                <span class="link-block">
                                    <a href="https://huggingface.co/datasets/m-a-p/Matrix" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">ü§ó</span>
                                        <span>Matrix</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a href="https://huggingface.co/collections/m-a-p/neo-models-66395a5c9662bb58d5d70f04" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">ü§ó</span>
                                        <span>Models</span>
                                    </a>
                                </span>

                                <!-- Github link -->
                                <span class="link-block">
                                    <a href="https://github.com/multimodal-art-projection/MAP-NEO" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon"><i class="fab fa-github"></i></span>
                                        <span>Code</span>
                                </a>
                                </span>

                                <!-- ArXiv abstract Link -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2405.19327" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                <span>arXiv</span>
                                </a>
                                </span>

                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Paper abstract -->
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                            <p>
                                Large Language Models (LLMs) have made great strides in recent years to achieve unprecedented performance across different tasks. However, due to commercial interest, the most competitive models like GPT, Gemini, and Claude have been gated behind proprietary interfaces without disclosing the training details. Recently, many institutions have open-sourced several strong LLMs like LLaMA-3, comparable to existing closed-source LLMs. However, only the model's weights are provided with most details ¬†(e.g., intermediate checkpoints, pre-training corpus, and training code, etc.) being undisclosed. To improve the transparency of LLMs, the research community has formed to open-source truly open LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training corpus and training code) are being provided. These models have greatly advanced the scientific study of these large models including their strengths, weaknesses, biases and risks. However, we observe that the existing truly open LLMs on reasoning, knowledge, and coding tasks are still inferior to existing state-of-the-art LLMs with similar model sizes. To this end, we open-source MAP-Neo, a highly capable and transparent bilingual language model with 7B parameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the first fully open-sourced bilingual LLM with comparable performance compared to existing state-of-the-art LLMs. Moreover, we open-source all details to reproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning pipeline, ¬†checkpoints, and well-optimized training/evaluation framework are provided. Finally, we hope our MAP-Neo will enhance and strengthen the open research community and inspire more innovations and creativities to facilitate the further improvements of LLMs.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->

    <section class="hero">
        <!-- <h2 class="title has-text-centered">The performance of base models on different benchmarks</h2> -->
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-four-fifths">
                        <!-- Text with embedded image -->
                        <div class="item">
                            <!-- Image with float right -->
                            <img src="static/images/radar.png" style="float: right; margin-left: 20px; max-width: 100%; height: auto;" />
                            <!-- Caption for image -->
                            <h2 class="subtitle" style="font-style: italic; clear: both;">
                                Figure 1. MAP-Neo shows impressive performance on base (Left) and chat (Right) models compared to both popular open-weight and recent transparent large language models with similar sizes.
                            </h2>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero">
        <h2 class="title has-text-centered">Matrix Data Pile</h2>
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-four-fifths">
                        <!-- Text with embedded image -->
                        <div class="item">
                            <!-- Image with float right -->
                            <img src="static/images/data_pile.png" style="float: right; margin-left: 20px; max-width: 100%; height: auto;" />
                            <!-- Caption for image -->
                            <h2 class="subtitle" style="font-style: italic; clear: both;">
                                Figure 2. Statistics of the Matrix Pile Data Distribution: The inner pie chart represents the language distribution, while the outer loop indicates the proportion of meta-categories in the corpus.
                            </h2>
                            <ul>
                                <!-- <li><strong>Data Quality</strong> -->
                                The final composition of the corpus is as follows: 52.55% from Common Crawl, 22.29% from programming code, and the rest from academic papers, books, and other printed materials, as illustrated in Figure 2. <br><br></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero">
        <h2 class="title has-text-centered">The performance of base models on different benchmarks</h2>
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-four-fifths">
                        <!-- Text with embedded image -->
                        <div class="item">
                            <!-- Image with float right -->
                            <img src="static/images/table9.png" style="float: right; margin-left: 20px; max-width: 100%; height: auto;" />
                            <!-- Caption for image
                            <h2 class="subtitle" style="font-style: italic; clear: both;">
                                Above is the data processing flow and deduplication ratios, below is a schematic diagram of similar line deduplication.
                            </h2> -->
                            <ul>
                                <li><strong>Data Quality</strong>
                                MAP-Neo demonstrates significantly better performance on math, code, and complex reasoning by incorporating high-quality data, compared to previous transparent LLMs, e.g. Amber and Pythia, adopting (presumably) lower quality data.<br><br></li>
                                <li><strong>Gap between our MAP-Neo and other transparent LLMs</strong><br>
                                We note that transparent LLMs still significantly lag behind the performance of frontier industrial Open-weight LLMs with similar sizes (e.g. LLama3-8B, Mistral-7B). In contrast, our MAP-Neo can match or even surpass them on part of the automatic benchmarks about math, code, and Chinese knowledge. We call for increased participation in the development of transparent LLMs to further advance the LLM democratization. <br><br></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero">
        <h2 class="title has-text-centered">The performance of aligned models on different benchmarks</h2>
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-four-fifths">
                        <!-- Text with embedded image -->
                        <div class="item">
                            <!-- Image with float right -->
                            <img src="static/images/table10.png" style="float: right; margin-left: 20px; max-width: 100%; height: auto;" />
                            <!-- Caption for image
                            <h2 class="subtitle" style="font-style: italic; clear: both;">
                                Above is the data processing flow and deduplication ratios, below is a schematic diagram of similar line deduplication.
                            </h2> -->
                            <ul>
                                <li><strong>The effectiveness of Iterative DPO</strong>
                                In Table 10, when compared to Neo-7B-SFT, Neo-7B-Instruct shows significant improvement on the chat-related benchmark datasets (e.g., AlignBench, AlpacaEval, Arena-Hard, and CHC-Bench), which further demonstrates the effectiveness of our Iterative DPO.<br><br></li>
                                <li><strong>The performance of the chat model</strong><br>
                                Table 10 shows that Amber-7B-Chat and OLMo-7B-Instruct perform poorly on Chat Benchmarks. We assume that the limited capabilities of the base model may severely limit the performance of corresponding instruction-tuned models on chat benchmarks. <br><br></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- BibTex citation -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            Please kindly cite our paper if you use our code, data, models or results:
            <br><br>
            <pre><code>
@article{zhang2024mapneo,
    title   = {MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series},
    author  = {Ge Zhang and Scott Qu and Jiaheng Liu and Chenchen Zhang and Chenghua Lin and Chou Leuang Yu and Danny Pan and Esther Cheng and Jie Liu and Qunshu Lin and Raven Yuan and Tuney Zheng and Wei Pang and Xinrun Du and Yiming Liang and Yinghao Ma and Yizhi Li and Ziyang Ma and Bill Lin and Emmanouil Benetos and Huan Yang and Junting Zhou and Kaijing Ma and Minghao Liu and Morry Niu and Noah Wang and Quehry Que and Ruibo Liu and Sine Liu and Shawn Guo and Soren Gao and Wangchunshu Zhou and Xinyue Zhang and Yizhi Zhou and Yubo Wang and Yuelin Bai and Yuhan Zhang and Yuxiang Zhang and Zenith Wang and Zhenzhu Yang and Zijian Zhao and Jiajun Zhang and Wanli Ouyang and Wenhao Huang and Wenhu Chen},
    year    = {2024},
    journal = {arXiv preprint arXiv: 2405.19327}
}
            </code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a>                            project page. You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                                target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>
<style>
    .buttonGroup {
        text-align: center;
    }
    
    .buttonGroup>button {
        padding: 15px;
        color: white;
        background-color: #363636;
        border-radius: 5px;
    }
    
    .buttonGroup>button:hover {
        box-shadow: 5px;
    }
</style>

</html>
